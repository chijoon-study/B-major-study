# 밑바닥부터 만드는 컴퓨팅 시스템(nand2tetris) 요약 정리

### 이 글은 무엇을 다루는가?

지금까지 nand2tetris 프로젝트를 하면서 하나에서 두 챕터마다 책의 내용을 요약하고 정리했다.

다만 책을 다 읽고 나서 다시 정리한 내용을 흝어보았고 단점 하나를 찾았는데, 요약본에선 각 챕터가 어떻게 연결되는지 잘 보이지 않았다.

그래서 요약본을 보완하기 위해 이 글에서는 "인상 깊었던 내용"과 "각 챕터가 어떻게 연결되는지"를 정리해보고자 한다.

## 총 정리

- 1장에서 기본적인 Chip을 구현한다.
- 2장에선 더 복잡한 Chip을 구현하고, 3장에선 시간 정보를 포함하는 Chip을 구현한다.
- 4장에선 앞으로 사용한 기계어를 정의한다.
- 5장에선 기계어를 처리할 수 있는 컴퓨터를 구현한다. (이 부분을 잘 이해해야 이후 장을 쉽게 이해할 수 있음)
- 6장에선 어셈블리어를 기계어로 변환하는 어셈블러를 만든다.
- 7~8장은 VM 언어의 정의와 변환기(VM -> 어셈블러)를 만든다.
- 9장은 Jack 언어를 정의하고, 10~11장은 변환기(Jack -> VM)을 만든다.
- 12장은 하드웨어 부분을 사용하기 쉽게 하는 Jack API(겸 OS)를 만든다.

개인적으로 느낀 건, Jack 구현이나 책에서 다루는 정의를 외우는 것보다.

고수준 언어가 어떤 과정을 거쳐 변환되는지?, 컴퓨터는 어떤 식으로 동작하는지? 고수준 언어의 if-else, function은 저수준 언어에서 어떻게 동작하는지? 등의 추상적인(?) 개념을 이해하는게 더 중요한 것
같다.

## 인상 깊었던 내용들 정리

- #### 모든 것은 추상화와 구현이다.
    - 네트워크 계층, 컴퓨터, OS 등 많은 부분이 구체적인 구현을 숨기고 추상화 된 기능을 제공한다.
    - 사용하는 입장에서 추상화 된 영역만을 사용해서 사용할 수 있기 떄문다.
    - 표준화, 복잡성 감소, 효율성(협업에서), 모듈화 및 재사용성 등의 장점을 가진다.
- #### 왜 2진법인가? - 사실 이건 다른 책 내용이긴 한데
    - 컴퓨터는 물리적인 실체를 가진다. 전압을 사용해서 상태를 표현한다.
    - On/Off를 표현하는게 중간 상태(3진법 이상의 수)를 가지는 것보다 구현하기 쉽기 때문이다.
        - 중간 상태를 가지게 할 수는 있으나 구현 난이도나 효율성 면에서 떨어지기 때문에 사용하지 않는다.
- #### 논리 게이트와 칩, 플립플롭
    - 컴퓨터는 2진수를 사용하므로 Boolean 논리를 기반으로 한 Gate 집합(=Chip)으로 구현된다.
    - 플립플롭은 상태를 저장할 수 있는 Chip이기 때문에 중요하다.
- #### 컴퓨터의 시간 개념 & 클록/사이클이란?
    - 컴퓨터는 이산적인 시간을 가진다. (실제 시간은 무한하게 나누고 표현할 수 있다.)
        - 이산적: 단절되는 것.
        - 연속적: 끊어지지 않고 계속되는 것.
    - 왜 이산적인 시간인가?
        - 컴퓨터는 물리적인 실체를 가지므로 연산을 수행하는데 있어서 전압을 높이고 줄이면서 상태를 변화시키는 과정이 필요하다.
        - 이때, 연산이 시작과 마무리 시점을 제외한 중간 변화(불일치)는 필요하지 않으므로 버려진다.
        - 이처럼 컴퓨터에선 시간이 단절되어 구분하기 때문에, 이산적인 시간을 가진다고 말한다.
    - 클록/사이클
        - 클록(clock)은 컴퓨터 시스템에서 일정한 주기로 발생하는 신호이다. 이 신호가 켜지고 커지는걸 tic-toc 이라고 하는데, CPU와 다른 하드웨어 구성 요소가 동작하는 속도를 조절한다.
            - 그래서 클록 속도가 빠를수록 많은 연산을 수행할 수 있다고 볼 수 있다.
            - 클록 주기를 기본 설정보다 높이거나 낮추는 오버클록 언더클록이 있다.
        - 사이클(cycle)은 클록 신호의 한 주기를 의미한다.
        - 컴퓨터는 클록 주기에 맞춰서 단절된 시간 흐름을 가진다.
- #### 컴퓨터는 어떻게 이루어져있고 어떻게 동작하는가?
    - 가장 기본적인 컴퓨터(폰 노이만 구조)는 다음과 같은 구성을 가진다.
        - CPU, RAM, Input/Output Device
        - CPU는 계산 상태를 저장하는 processor register, ALU(산술 연산 장치)로 구성된다.
        - RAM는 register의 집합이다. (register는 플립플롭을 사용해서 만들어진다.)
            - 휘발성을 띄며, 값과 프로그램을 저장한다.
            - 왜 "Random Access" Memory인가?
                - 어느 주소이던 동일한 시간으로 접근 가능하기 때문이다.(demultiplexer를 사용한다.)
        - Input/Output Device
            - 입출력에 사용된다.
        - 컴퓨터의 동작 과정
            1. 명령 수행 요청: CPU에게 프로그램 실행 요청이나 인터럽트(중단 요청)이 전송된다. 프로그램 실행 요청의 경우 아래 순서를 따라 진행되고, 인터럽트의 경우 현재 진행을 잠시 중지하고
               인터럽트 서비스 루틴(
               Interrupt Service Routine, ISR)으로 이동하여 연산을 처리한다.
            2. CPU의 작업 수행: CPU는 받은 명령에 따라 다양한 작업을 수행합니다. 이에는 산술/논리 연산, 메모리 접근(읽기/쓰기), 레지스터 간의 데이터 전송 등이 포함됩니다. 명령어는 CPU
               내부의 명령어
               레지스터(Instruction Register)에 저장되어 해독되고 실행됩니다.
            3. 상태 변경: CPU의 작업으로 인해 메모리나 레지스터 등의 상태가 변경된다. 연산 결과의 저장, 레지스터 간의 데이터 이동 등이 포함된다.
            4. 다음 명령 실행 준비: Program Counter는 다음에 실행할 명령어의 주소를 가리키도록 업데이트된다. 그럼 CPU는 다음 명령어를 실행할 준비가 된다.
        - bootstrap - 컴퓨터는 어떻게 실행되는가?
            - (사실 이 곳에 있을만한 내용은 아니긴 한데)
            - 컴퓨터가 켜지면 BIOS/UEFI ROM(Read Only Memory)에 있는 Firmware를 실행한다. (주로 메인보드에 있음)
            - Firmware는 하드웨어의 상태를 확인하고 OS를 로드하기 위한 부트로더를 찾아 로드한다.
            - 부트 로더는 OS를 메모리에 올리고 설정(초기화)한다.
            - OS의 준비가 완료되면 우리가 컴퓨터를 사용할 수 있다.
- #### 기계어와 어셈블리어란?
    - 기계어는 CPU가 이해하는 언어이다.
        - 여러 아키텍처가 있다. (x86, arm64 등) -
          추천 [블로그 자료](https://velog.io/@480/%EC%9D%B4%EC%A0%9C%EB%8A%94-%EA%B0%9C%EB%B0%9C%EC%9E%90%EB%8F%84-CPU-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98%EB%A5%BC-%EA%B5%AC%EB%B6%84%ED%95%B4%EC%95%BC-%ED%95%A9%EB%8B%88%EB%8B%A4)
            - 아키텍처의 종류로는 크게 CISC는 RISC가 있다.
            - CISC(Complex Instruction Set Computer)
                - 복잡(많음)하고 강력한 명령어 집합을 제공하는 아키텍처
                - x84(intel꺼), x86-64(amd꺼) 등이 해당된다.
            - RISC(Reduced Instruction Set Computer)
                - 단순(적음)하고 비슷한 길이의 명령어 집합을 제공하는 아키텍처
                - arm64 등이 해당된다.
            - CISC vs RISC
                - RISC 자체가 CISC의 단점(예전엔 장점이였을 수도 있으나)을 보완해서 새로 나온 개념이므로 더 효율적이다.
                - RISC가 더 좋다, 내부적으로 일부 CISC(x86, x86-64)도 명령어를 쪼개서 RISC처럼 단순하게 동작한다.
                - 파이프라이닝이라는 걸 통해서 한 작업을 여러 단계로 나눠서 동시에 처리할 수 있다. (이 표현이 정확한지는 모르겠다. 이 부분 기억이 잘 안나면 따로 찾아보자.)
                - 하지만 CISC는 명령어 개수가 많고 명령어마다 길이가 달라서 파이프라이닝을 잘 처리하지 못한다. 또 구현이 어렵다는 단점도 있다.
    - 기계어를 사람이 사용하기 쉽게 기계어를 특정 기호로 대체하여 표현한 것이 어셈블리어이다. (어셈블리 + 언어)
        - 어셈블리어를 기계어로 변환하는 프로그램을 어셈블러라고 부른다.
    - 결국 모든 프로그래밍 언어는 기계어로 변환된다.
        - 고수준 언어의 함수, 클래스, 모듈 등의 모든 기능은 기계어의 제한적인 연산으로 이루어진다.
    - 어셈블리어의 연산에는 어떤 것이 있나?
        - 산술 및 논리 연산, 메모리 접근, 흐름 제어가 있다.
        - 또한 하드웨어에 의존하지 않기 위한 기능을 제공한다. 심볼릭 상수(symbolic constant), 레이블(label) 등
- #### 가상머신과 가상머신 언어
    - 가상머신의 필요성/효율성
        - 고수준 언어와 기계어의 중간에 위치하며, 추상화 계층을 제공하는 역할을 한다.
        - 컴퓨터 시스템 입장에선 VM 환경만 구현하면 된다. (더 복잡한 고수준 -> 저수준 변환 로직 대신)
        - 여러 고수준 언어는 동일한 VM 언어로 변환되어 VM 환경에서 실행될 수 있다. (예시: JVM 기반의 Java, Kotlin, Groovy 등)
    - 스택 기반 VS 레지스터 기반
        - 스택 기반의 가상머신이 적당히 고수준이면서 저수준이기 때문에 자주 사용한다.
        - 레지스터 기반 가상머신도 사용하긴 하나 잘 사용하지 않는다. (안드로이드처럼 더 고성능이면서 제한적인 환경에서 잘 동작하도록 하는 경우 사용할 수 있다.)
    - 이전 조금 다른 이야기지만, LLVM이라는게 있다.
        - 이름과 달리 가상머신은 아니다. 대신 IR을 하드웨어 환경에 맞게 효율적으로 변환해주는 기능을 제공한다.
          - 즉, VM의 장점과 비슷하게, 고수준 언어를 기계어로 변환하는 과정을 단순화 or 표준화 해준다.
        - IR(중간 표현)를 제공해서 기계어로 변환하거나 런타임 시점에 다른 프로그래밍 언어에서 실행되도록 할 수도 있다.
        - C/C++에서도 사용하고 있고, Python, Rust, Swift도 사용하고 있다.
        - 자바의 AOT 컴파일러인 GraalVM에선 GraalVM LLVM Runtime 기능을 사용해서 LLVM 코드를 실행할 수도 있다. 즉, LLVM으로 변환되는 많은 프로그래밍 언어를 실행할 수 있다.
        - 참고한 자료
          - [“프로그래밍 언어 개발의 감초” LLVM의 이해와 활용 방법](https://www.itworld.co.kr/news/304285#csidx1f550d687f8d24fa81ba06d862e00ea) 
          - [LLVM in 100 Seconds](https://youtu.be/BT2Cv-Tjq7Q?si=bGXOzsJokhy7_lJ5)
- #### Call Stack
    - 특정 메서드(함수, 서브루틴)이 수행되는 과정
        - 피호출자에게 전달할 인수(argument)와 호출자의 상태를 저장하고, 피호출자의 위치로 이동한다.
        - 피호출자 위치에서 인수를 가져와 연산을 처리하고 결과를 정해진 위치(책에선 첫번째 인수)에 저장한다.
        - 이후 호출자의 상태를 다시 로드하고, 호출자가 메서드를 호출한 이후의 명령어부터 이어서 실행된다.
    - 각 함수 호출은 호출자의 정보와 호출된 함수의 로컬 변수 등을 포함하는 프레임으로 구성된다.
    - 이러한 프레임이 스택 자료구조에 쌓여서 관리되므로 Call Stack 이라고 부른다.
- #### 포인터, 참조 타입에 대한 개인적인 생각
    - (여기서 말하는 포인터나 참조 타입은 특정 언어의 문법보다는 값에 메모리를 저장하는 방식이라고 보는게 나을 듯. 컴파일러 구현하는 입장에서 느낀 개인적인 생각이다.)
    - 포인터를 사용하면 어떤 큰 값을 표현할 때, 일반적인 값 타입과 동일한 크기로 다룰 수 있다.
        - 계산을 처리하는 특정 영역에서 관리하지 않고 따로 Heap 같은 곳에 저장하고 주소 값을 저장해서 사용하면, 아무리 큰 데이터라도 문제없이 표현할 수 있다.
    - 다른 영역(주로 Heap)에 저장된 큰 데이터를 여러 영역에서 동시에 참조하여 효율적으로 처리할 수도 있다. (예시: Java의 인스턴스나 String Pool)
        - 다만 이 경우 동시성 문제가 발생할 수도 있다. (여러 곳에서 참조하면서 불변인 경우)
- #### 고수준 언어의 기능은 (저수준 언어에서) 어떻게 구현(컴파일)되는가?
    - 고수준 언어의 기능은 배열, 클래스, 함수, if, while 등이 있다.
    - (주로 프로세스 메모리 구조의 Stack과 Heap을 중점적으로 다룬다.)
    - 배열
        - 생성 시 Heap에 적절한 영역을 할당받는다.
        - 실체는 Heap에 저장되고, (Stack 영역의)변수는 포인터 값으로 배열의 시작 위치를 저장한다.
    - 클래스
        - 배열과 동일하게 Heap에 적절한 영역을 할당받는다.
            - 클래스 안에 다른 객체가 있는 경우 이것도 독립적인 Heap 공간을 점유하고 클래스의 필드에는 포인터 값이 저장된다.
    - 함수
        - 특정 함수 호출 시 Call Stack이 쌓인다.
        - 프로그램 코드(PC)가 그 함수 코드가 위치한 곳으로 이동해서 처리하고 끝나면, 다시 호출자의 코드로 이동해서 다음 코드를 읽는다.
    - if, while
        - if-else는 저수준 언어의 if와 label로 구현된다.
            - 특정 조건에 해당되는 경우 if 블록에 속하는 코드가 실행되고, 아니면 else가 정의된 코드로 이동해서 실행된다.
        - while도 if-else와 비슷하게 저수준 언어의 if와 label로 구현된다.
            - 대신 조건에 맞는 동안 같은 코드 블럭을 반복해서 실행한다는 차이가 있다.
- #### 컴파일러와 인터프리터
    - 기계어로 번역되는 시점의 차이가 있다고 생각한다.
    - 컴파일러: 미리 목적언어(기계어나 VM언어 등)로 번역, 그만큼 효율적임, 대신 컴파일된 기계어는 다른 환경에서 실행되지 않음.
    - 인터프리터: 프로그램이 실행되면서 필요할 때 기계어로 번역, 실행 도중에 번역 과정이 있어서 느리다. 대신 하드웨어 환경에 영향받지 않음.
        - 하드웨어 환경에 무관한건 언어나 사용자 입장이고, 인터프리터 개발자는 각 환경에 맞는 프로그램을 개발해야 함. (그건 컴파일러 개발자도 마찬가지)
    - 특정 언어를 컴파일러와 인터프리터로 나눌 수 없음.
        - 자바만 해도 컴파일해서 VM언어로 바꾸고, JVM 내에서 인터프리터가 기계어로 번역함.
        - 둘 중에 하나만 채택할 수 있는게 아님, 그냥 그 언어의 특징을 이해하기.

(위에서 정리한 내용은 주로 nand2tetris에서 인상깊었던 내용이지만, Google It Support, 혼자 공부하는 컴퓨터 구조와 운영체제, 한 권으로 읽는 컴퓨터 구조와 프로그래밍 등의 내용이 포함되었을
수도 있음. 이전에 봤던 자료와 연관되서 더 기억에 잘 남은걸수도 있고... 또, 개인적인 생각도 조금 섞였다.)

## 1장: Boolean Logic - 불 논리

컴퓨터는 0과 1만을 사용하는 수 체계인 이진법을 사용한다.

아날로그 신호를 쉽게 처리할 수 있기 때문이다. (= 하드웨어 설계의 복잡성 감소)    
(아날로그 신호를 3가지 이상의 상태(N진법)로도 표현할 수 있겠지만, 그런 중간 값을 처리할 수 있는 부품의 가성비가 On/Off의 기기에 비해서 좋지 않다.)

불 대수(Boolean Algebra)는 논리학에서 참 거짓을 나타내는 데 사용되고, 하드웨어 개발에도 사용된다.    
(대수: 일련의 연산들이 주어진 집합)

게이트(Gate): 불 함수를 하드웨어로 구현한 물리적 장치. 칩(chip)이라고도 부른다.

이러한 Chip들의 집합으로 여러 이진 연산을 처리하는 더 복잡한 칩을 만들 수 있다.

**요약: 2진법을 기반으로 한 Chip을 구현한다.**

## 2장: Boolean Arithmetic - 불 연산

범용 컴퓨터 시스템은 여러 산술 연산(부호 + 사칙연산)을 지원해야 한다.

수학에서 숫자는 무한하지만 컴퓨터에서는 유한한 고정 단어 크기(word size)를 사용하므로 무한하지 않다.    
(32bit, 64bit 컴퓨터라고 부를 때, 이 비트 수가 word size를 나타낸다.)

고정 단어 크기보다 더 큰 범위의 값을 사용하기 위해 고수준 언어는 추상화 기법을 지원한다.

2진수의 덧셈은 가산기(종류가 많음), 뻴셈은 2의 보수와 덧셈을 사용해서 구현할 수 있다.

컴퓨터는 모든 연산을 처리하는 CPU(중앙 처리 장치, Central Processing Unit)에서 ALU(산술 논리 장치, Arithmetic Logic Unit) Chip을 사용해 모든 산술 및 논리 연산을
처리한다.

**요약: Chip의 집합으로 산술 및 논리 연산을 수행하는 ALU를 만든다.**

## 3장: Memory - 메모리

컴퓨터가 더 반복적이고 큰 규모의 작업을 하기 위해서 중간 작업을 기억해야만 한다.        
따라서 이전 시간의 비트 정보를 저장하는 Chip이 필요한데, 이를 플립플롭이라고 부른다.

실제 시간은 무한하게 나눌 수 있다.     
하지만 컴퓨터의 자원은 제한적이므로, 컴퓨터는 이산적인 시간(Discrete time)을 가진다.

한 사이클이 이루어지는 동안, 내부적으로 전압이 변화하고 계산이 이루어진다. 하지만 이 중간 상태는 필요하지 않고, 결과만 필요하므로 중간 변화는 무시된다.      
이를 통해 이산적인 시간을 가질 수 있다.

**요약: 이전 시간(사이클)의 값을 기억하는 플립플롭을 사용해서 값을 저장하는 레지스터, 레지스터의 집합인 RAM, 카운터 등의 Chip을 구현할 수 있다.**

## 4장: Machine Language - 기계어

컴퓨터가 이해하는 언어를 기계어라고 한다.

기계어를 특정 문자(기호)로 변환하여 사람이 쉽게 읽고 쓸 수 있는 언어를 어셈블리어(assembly language)라고 한다.

이런 기계어와 어셈블리어(저수준 언어)는 하드웨어(CPU)와 밀접한 연관이 있어서, CPU의 종류가 달라지면 언어도 달라진다.

이런 기계어는 산술 및 논리 연산, 메모리 접근, 흐름 제어(goto, label), 기호(하드웨어의 메모리 주소를 의존하지 않음, goto문 같은거 수행할 때)을 지원한다.

**요약: CPU가 이해하는 기계어와 인간에게 친숙하게 변환한 기계어인 어셈블리어를 정의한다. 이를 통해 산술/논리 연산, 메모리 접근, 흐름 제어가 가능하다. 이는 이후 개발한 모든 고수준 언어의 기능을 처리할 수 있다.**

## 5장: Computer Architecture - 컴퓨터 구조

(5장 내용 관련해서는 혼자 공부하는 컴퓨터 시스템, 운영체제 책을 조금 참고)

컴퓨터가 무엇인지는 생략하겠다. 5장 요약 정리를 보자.

#### 컴퓨터가 어떻게 동작하는가?

아래 내용은 매 사이클마다 반복된다.

1. 명령 수행 요청: CPU에게 프로그램 실행 요청이나 인터럽트(중단 요청)이 전송된다. 프로그램 실행 요청의 경우 아래 순서를 따라 진행되고, 인터럽트의 경우 현재 진행을 잠시 중지하고 인터럽트 서비스 루틴(
   Interrupt Service Routine, ISR)으로 이동하여 연산을 처리한다.
2. CPU의 작업 수행: CPU는 받은 명령에 따라 다양한 작업을 수행합니다. 이에는 산술/논리 연산, 메모리 접근(읽기/쓰기), 레지스터 간의 데이터 전송 등이 포함됩니다. 명령어는 CPU 내부의 명령어
   레지스터(Instruction Register)에 저장되어 해독되고 실행됩니다.
3. 상태 변경: CPU의 작업으로 인해 메모리나 레지스터 등의 상태가 변경된다. 연산 결과의 저장, 레지스터 간의 데이터 이동 등이 포함된다.
4. 다음 명령 실행 준비: Program Counter는 다음에 실행할 명령어의 주소를 가리키도록 업데이트된다. 그럼 CPU는 다음 명령어를 실행할 준비가 된다.

(단, nand2tetris에서는 인터럽트는 고려하지 않는다.)

**요약: 4장에서 정의한 기게어의 명세에 맞게, RAM, CPU, ROM 등의 Chip을 사용해서 컴퓨터를 만든다.**

## 6장: Assembler - 어셈블러

고수준 언어를 사용해서 어셈블러를 만드는데, 그럼 처음에 이 고수준 언어는 어떻게 만들어졌을까?    
이는 [bootstrapping](https://ko.wikipedia.org/wiki/%EB%B6%80%ED%8A%B8%EC%8A%A4%ED%8A%B8%EB%9E%A9_(%EC%BB%B4%ED%8C%8C%EC%9D%BC%EB%9F%AC))
이라는 과정을 통해 가능해진다.

**요약: 어셈블리어를 기계어로 변환하는 어셈블러를 만든다.**

## 7~8장: Virtual Machine - 가상 머신

가상머신은 고수준 언어와 대상 기계어의 영역을 분리하는 중간 인터페이스이다.

주로 스택 기반의 가상머신을 많이 사용하고, nand2tetris에서도 스택 기반의 가상머신을 구현한다.

VM언어 자체가 어셈블리어에 가까운 언어라서 구현을 이해하는게 크게 어렵지 않다.

**요약: 가상머신을 기계어로 변환하는 변환기를 고급 언어로 구현한다.**

## 9장: High-Leval Language - 고수준 언어

**요약: nand2tetris에서 정의한 Jack 언어를 통해 간단한 프로젝트를 만든다.**

## 10~11장: Compiler - 컴파일러

고수준 언어를 VM 언어로 변환하는 컴파일러를 만든다.

VM 언어는 상대적으로 저수준 언어에 가까워서 구현 난이도가 높다.

파서, 심볼 테이블, 고수준 기능(if-else, function)을 저수준 기능으로 변환하는 과정을 구현하는게 어렵다.

**요약: Jack 언어를 VM 코드로 변환하는 변환기를 구현한다.**

## 12장: Operating System - 운영 체제

운영체제는 "하드웨어에 종속된 저수준 서비스를 프로그래머에게 친숙한 소프트웨어 서비스로 캡슐화해주는 프로그램"이라고 볼 수 있다.

현대 운영체제는 멀티 프로세스, 가상 메모리 & 메모리 페이징, 파일 시스템 등 여러 기능을 제공한다. 하지만 이 역시 하드웨어에 대한 추상화로 볼 수 있다.

(운영체제 가장 쉬운 3가지 에서는 가상화, 병행성, 영속성에 대한 추상화를 제공한다고 표현하기도 한다.)

**요약: 하드웨어에 대한 추상화를 제공해주는 Jack API를 개발한다.**

