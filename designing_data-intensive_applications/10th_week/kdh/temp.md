## stream processing
10챕터에서는 배치 프로세싱에 대해 알아봤었는데, 사실 실제 서비스에서 데이터의 흐름은 배치 프로세스와는 비슷하지 않다.  
데이터는 매분 매초 생성될 수 있기 때문이다.  
배치 프로세스는 보통 하루의 마지막에 실행시키기에 input이 output에 적용되는 건 하루 뒤이다.  

## producer, consumer
stream processing에 대해 이야기하는 만큼 데이터가 생성되자마자 실시간으로 db나 처리하는 곳으로 보내줘야할텐데, 기존엔 poll이라는 방식으로 진행했었다.  
데이터가 필요한 노드에서 데이터가 있는 곳에 계속해서 요청하며 있는지 확인하는 것이다.  
하지만 이 주기가 짧아질수록 새로운 데이터가 return되는 비율은 적어질 것이고 그만큼 overhead의 크기만 커질 것이다.  

때문에 데이터가 있는 곳에서 데이터가 새로 생성됐으면 필요한 노드에 알려주는 방식이 고안되었다.  
기존 db들은 triggers란 이름의 데이터의 변경에 react할 수 있는 기능이 있지만 직접적으로 stream processing을 위해 디자인 된것은 아니므로 불충분했다.  
때문에 데이터가 생성됐다는 event를 알리기 위한 여러 툴이 개발됐다.  

## message broker
가장 간단하게는 데이터가 생성되는 생성자 측에서 새로운 데이터가 생기면 데이터를 소비하는 소비자 측에 메세지를 직접 전달하는 방식이 있다.  
하지만 이는 치명적인 단점이 있는데,  
- 메시지가 유실 될 수 있는 가능성을 고려하여 애플리케이션 코드를 작성해야 한다.
- 소비자가 오프라인이라면 메시지를 전달하지 못하는 상태에서 있는 동안 전송된 메시지는 잃어 버릴 수 있다.

때문에 메세지 브로커라는 메시지 스트림을 처리하는데 최적화된 데이터베이스를 사용하게 된다.  
메세지 브로커는 또다른 노드에서 돌아가게 되고 생성자와 소비자는 브로커의 클라이언트로 접속하게 된다.  

브로커를 이용함으로서 얻는 이점은 
- 클라이언트의 상태 변경에 쉽게 대처할 수 있다.
- 브로커에 장애가 일어나도 기존에 메세지를 디스크에 기록하고 있었다면 유실되지 않는다.

## partitioning
분산환경에선 보통 디스크 하나로는 부족하니 브로커도 당연하게 파티셔닝 기법을 사용한다.  
다른 파티션은 다른 장비에서 서비스할 수 있다.  

## offset
![](offset.png)
각 파티션 내에서 브로커는 모든 메세지에 단순히 증가하는 번호인 offset을 부여한다.  
이는 파티션 내에서만 유효하고 다른 파티션 간 메세지의 순서는 보장하지 않는다. (서로 인과성이 없는 데이터라면 순서도 상관이 없으니)  
이 오프셋 덕에 어떤 메세지가 처리되고 안됐는지에 대한 오버헤드를 크게 줄일 수 있다.

## fall behind consumer
생성자가 만드는 데이터에 비해 소비자의 데이터 처리 속도가 더 느리다면 점점 예전 데이터를 읽게된다.  
데이터를 디스크에 쓴다해도 오래된 데이터는 삭제하거나 아카이브용 노드에 옮기는 등 브로커에서는 삭제될 수 있다.  
만약 소비자가 너무 늦어진다면 데이터가 drop되는 현상도 일어날 수 있다는 것이다.  
때문에 만약 이 경우 경고를 하게끔 만들어 소비자가 너무 늦어지는 현상을 해결해야한다.  
이 때 소비자가 늦어진다해도 해당 파티션을 제외한 나머지에는 영향을 주지않기에 운영적으로 편리하다.  