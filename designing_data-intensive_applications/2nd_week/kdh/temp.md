데이터베이스가 해야할걸 정말 간단하게 설명하면 데이터를 줬을때 저장하고 다시 달라했을때 돌려주는 것

가장 간단한 데이터 베이스는 쓰기 시 파일에 append only하고 읽기 의 경우 파일을 풀스캔해 키에 맞는 값을 반환해주는 거  
이 방법보다 쓰기가 간단해질 수는 없지만(가장 빠르지만) 읽기의 경우 정말 느림 big o 표기법으로는 O(n)  
때문에 다른 데이터 구조(인덱스)가 필요, 데이터 구조라는 것은 보통 추가적인 메타 데이터를 저장하는 것  
때문에 보통 쓰기 성능이 더 느려짐   

76 페이지에 데이터파일이 disk의 한계치를 넘기지 않기 위해 세그먼트로 나누고 압축하는 걸 설명하는데  
다 찼을때 압축하지말고 그냥 key값을 기준으로 빠르게 데이터 찾을 수 있으니까 update하면 안되나?  
(압축하는 방식이 그냥 key별로 가장 최근의 value들을 남기는 방식임)  
인데 이게 77페이지에 설명이 나옴  
총 3가지 이유가 있는데  
1. append, merge는 sequential 연산이라 random access보다 빠름
2. 동시성과 장애 복구가 훨신 간단함 e.g) 값이 덮어씌어지고 있을때 에러 발생하면 append방식의 경우 이전 버전과 덮어 씌어진 이후 버전 둘중 하나를 고를 수 있음
3. 세그먼트를 merge하는건 단편화를 막아줌  

78페이지에 데이터를 머지할때 정렬하는 알고리즘이  
1. 여러 세그먼트를 나란히 읽음(세그먼트는 key:value의 연속이므로 각 파일마다 하나의 key를 읽는 다는소리)
2. key들중 가장 작은 key를 output file에 복사함
3. 반복

인데 작은 키가 뒤쪽에 있으면?  
즉 세그먼트가 두개 있고 각 키가  
1. 6 9 3 2 1
2. 4 8 7 5

이렇게 있다고 하면 위 방법대로했을때  
4 6 8 7 9 3 2 1이 되는데?

인데 이게 또 80페이지에 설명이 나옴  
인메모리 balanced tree에 데이터를 저장한다고함(red-black 트리 같은)  
그리고 balanced tree가 일정 threshold(보통 몇 메가 바이트)를 넘으면 그때 disk에 쓰기 작업 수행



단어가 좀 틀려도 찾을 수 있는 인덱스??


인메모리 db의 성능 향상의 주요원인은 디스크 읽기 배제가 아니다??


star schema - fact table을 중심으로 dimension table들이 있는 구조
snowflake schema - star schema의 dimension table들이 더 세분화 된 구조

date table을 디멘션 테이블로 뺐을때 장점 : date에 좀더 다양한 정보를 표현할수 있음 e.g) is_holiday


columnar db에서 정렬할때 각 열마다 따로 하면 안된다하는데 한 열 집합에서 각 행에 원래 순서를 기억하게끔 하면 안되나?  
순서 정보가 더해져야해서 비 효율적인가?(각 열 집합마다 순서 정보를 붙여주는거니까 column * 2되는거라 비효율적이긴 할듯..)


columnar db를 정렬하고 난 이후엔 그럼 쓰기가 추가되면?  
-> lsm tree


columnar db에서 캐싱은 materialized view라는 이름 으로 불림  
rdb에서의 view와 다르게 실제로 쿼리 결과가 복사돼 디스크에 저장됨  
하지만 그 뷰를 이루는 데이터가 수정 됐을때 materialized view도 수정 되어야하고 이는 매우 비싼 쓰기 비용을 초래하므로 OLTP에선 잘 안쓰임  
하지만 읽기 부하가 큰 dw에선 이게 잘 쓰일 수 있음(근데 dw가 write연산이 더 많은거 아니었나)

