데이터베이스가 해야할걸 정말 간단하게 설명하면 데이터를 줬을때 저장하고 다시 달라했을때 돌려주는 것

가장 간단한 데이터 베이스는 쓰기 시 파일에 append only하고 읽기 의 경우 파일을 풀스캔해 키에 맞는 값을 반환해주는 거  
이 방법보다 쓰기가 간단해질 수는 없지만(가장 빠르지만) 읽기의 경우 정말 느림 big o 표기법으로는 O(n)  
때문에 다른 데이터 구조(인덱스)가 필요, 데이터 구조라는 것은 보통 추가적인 메타 데이터를 저장하는 것  
때문에 보통 쓰기 성능이 더 느려짐   

76 페이지에 데이터파일이 disk의 한계치를 넘기지 않기 위해 세그먼트로 나누고 압축하는 걸 설명하는데  
다 찼을때 압축하지말고 그냥 key값을 기준으로 빠르게 데이터 찾을 수 있으니까 update하면 안되나?  
(압축하는 방식이 그냥 key별로 가장 최근의 value들을 남기는 방식임)  
인데 이게 77페이지에 설명이 나옴  
총 3가지 이유가 있는데  
1. append, merge는 sequential 연산이라 random access보다 빠름
2. 동시성과 장애 복구가 훨신 간단함 e.g) 값이 덮어씌어지고 있을때 에러 발생하면 append방식의 경우 이전 버전과 덮어 씌어진 이후 버전 둘중 하나를 고를 수 있음
3. 세그먼트를 merge하는건 단편화를 막아줌  

78페이지에 데이터를 머지할때 정렬하는 알고리즘이  
1. 여러 세그먼트를 나란히 읽음(세그먼트는 key:value의 연속이므로 각 파일마다 하나의 key를 읽는 다는소리)
2. key들중 가장 작은 key를 output file에 복사함
3. 반복

인데 작은 키가 뒤쪽에 있으면?  
즉 세그먼트가 두개 있고 각 키가  
1. 6 9 3 2 1
2. 4 8 7 5

이렇게 있다고 하면 위 방법대로했을때  
4 6 8 7 9 3 2 1이 되는데?

인데 이게 또 80페이지에 설명이 나옴  
인메모리 balanced tree에 데이터를 저장한다고함(red-black 트리 같은)  
그리고 balanced tree가 일정 threshold(보통 몇 메가 바이트)를 넘으면 그때 disk에 쓰기 작업 수행
